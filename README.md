# Big Data & Machine Learning with Apache Spark

## Overview
This project consists of three major tasks leveraging **Apache Spark** for large-scale data processing, machine learning, and distributed computing.

1. **Data Processing with Spark DataFrames**
2. **Machine Learning with Spark MLlib**
3. **Apache Spark RDD Operations**

Each task demonstrates how to efficiently handle and analyse large datasets using **Spark's distributed computing framework**.

## Task 1: Data Processing with Spark DataFrames
- **Objective**: Perform large-scale **data cleaning, transformation, and aggregation** using **Spark DataFrames**.
- **Key Features**:
  - Data ingestion from structured sources.
  - SQL-like transformations and aggregations.
  - Performance optimisations via partitioning and caching.
- **Results**: Efficient data manipulation and querying using Spark DataFrames.

## Task 2: Machine Learning with Spark MLlib
- **Objective**: Build and evaluate **machine learning models** on large datasets using **Apache Spark MLlib**.
- **Key Features**:
  - Feature selection and normalisation.
  - Model training: **Logistic Regression, Decision Trees, Random Forest, Gradient Boosting**.
  - Hyperparameter tuning using **Grid Search and Cross-Validation**.
- **Results**: Trained scalable ML models with optimised parameters and performance evaluation.

## Task 3: Apache Spark RDD Operations
- **Objective**: Understand **RDD transformations and actions** to process big data efficiently.
- **Key Features**:
  - Creating RDDs and understanding partitioning.
  - Transformations: `map()`, `filter()`, `flatMap()`, `reduceByKey()`.
  - Actions: `collect()`, `count()`, `reduce()`.
- **Results**: Improved data processing speed using **parallel computing and distributed execution**.

## Requirements
- **Apache Spark** (Standalone or on a cluster)
- **Python 3.x** with `pyspark`
- Libraries: `pandas`, `numpy`, `matplotlib`, `seaborn`

## Usage
1. Open the relevant Jupyter Notebooks:
   - `Mohammed-Adnan-Englampurath_Dataframe.ipynb`
   - `Mohammed-Adnan-Englampurath_ML.ipynb`
   - `Mohammed-Adnan-Englampurath_RDD.ipynb`
2. Execute the notebooks step by step to **process data, train models, and evaluate performance**.
3. Analyse insights through **visualisations and Spark queries**.

## Results
- **Efficiently processed large datasets** using **Spark DataFrames & RDDs**.
- **Built scalable machine learning models** with **MLlib**.
- **Optimised performance** using **partitioning, caching, and distributed computing**.

## References
- **Apache Spark Official Documentation**: [https://spark.apache.org/](https://spark.apache.org/)
- **Machine Learning with MLlib**: [https://spark.apache.org/mllib/](https://spark.apache.org/mllib/)
- **RDD Programming Guide**: [https://spark.apache.org/docs/latest/rdd-programming-guide.html](https://spark.apache.org/docs/latest/rdd-programming-guide.html)

---

